{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\OneDrive - Process Point Technologies\\vlm-ppe-analysis-toolkit\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from IPython.display import HTML, display\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "import os\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    \"\"\"Convert image to base64\"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        return img\n",
    "\n",
    "\n",
    "def load_model(model_name, model_cache_dir=r\"C:\\Users\\shrey\\.cache\\huggingface\\hub\"):\n",
    "    \"\"\"Loads the model and tokenizer from cache or downloads them\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        model_name, \n",
    "        cache_dir=model_cache_dir\n",
    "    )\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        model_name, \n",
    "        device_map=\"auto\", \n",
    "        cache_dir=model_cache_dir\n",
    "    )\n",
    "    model.to(device)\n",
    "    return model, processor\n",
    "\n",
    "\n",
    "def analyze_image(image_path, model, processor):\n",
    "    \"\"\"Analyze single image with Given Model\"\"\"\n",
    "    try:\n",
    "        # Encode image\n",
    "        image_name = Image.open(image_path)\n",
    "        \n",
    "        # Create messages for the model consumption\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"}, \n",
    "                    {\n",
    "                        \"type\": \"text\", \n",
    "                        \"text\": \"Please describe in particular, the protective equipment being worn, if present.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Prepare inputs for the model\n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        model_inputs = processor(text=[text],images=[image_name], padding=True, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Generate response\n",
    "        generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n",
    "        response_text = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        return response_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {image_path}: {e}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def process_folder(folder_path, model, processor, limit=None): \n",
    "    \"\"\"Process all images in folder and return results or exit at the number specified\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Support multiple image extensions\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "\n",
    "    # Get all image files\n",
    "    image_files = [\n",
    "        f for f in Path(folder_path).rglob('*')\n",
    "        if f.suffix.lower() in image_extensions\n",
    "    ]\n",
    "    \n",
    "    if limit:\n",
    "        image_files = image_files[:limit]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images to process\")\n",
    "    \n",
    "    for i, image_path in enumerate(image_files, 1):\n",
    "        print(f\"Processing image {i}/{len(image_files)}: {image_path.name}\")\n",
    "        \n",
    "        analysis = analyze_image(image_path, model, processor)\n",
    "        \n",
    "        results.append({\n",
    "            'image_path': str(image_path),\n",
    "            'analysis': analysis\n",
    "        })\n",
    "        \n",
    "        time.sleep(0.5)  # Small delay to avoid overwhelming the API\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_html(results):\n",
    "    \"\"\"Generate HTML display of results\"\"\"\n",
    "    html = \"\"\"\n",
    "    <style>\n",
    "        .result-container {\n",
    "            display: flex;\n",
    "            margin-bottom: 20px;\n",
    "            border: 1px solid #ddd;\n",
    "            padding: 10px;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "        .image-container {\n",
    "            flex: 0 0 400px;\n",
    "            margin-right: 20px;\n",
    "        }\n",
    "        .image-container img {\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "        }\n",
    "        .analysis-container {\n",
    "            flex: 1;\n",
    "            padding: 10px;\n",
    "        }\n",
    "        .analysis-text {\n",
    "            white-space: pre-wrap;\n",
    "            font-family: Arial, sans-serif;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    \n",
    "    for result in results:\n",
    "        html += f\"\"\"\n",
    "        <div class=\"result-container\">\n",
    "            <div class=\"image-container\">\n",
    "                <img src=\"file://{result['image_path']}\" alt=\"Image\">\n",
    "                <p><small>{Path(result['image_path']).name}</small></p>\n",
    "            </div>\n",
    "            <div class=\"analysis-container\">\n",
    "                <div class=\"analysis-text\">{result['analysis']}</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "\n",
    "def save_html(html_content, model_name, output_path):\n",
    "    \"\"\"Save HTML to file\"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>{model_name} Image Analysis Results</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>{model_name} Image Analysis Results</h1>\n",
    "        \"\"\" + html_content + \"\"\"\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:  60%|██████    | 3/5 [08:08<06:26, 193.24s/it]"
     ]
    }
   ],
   "source": [
    "# Set the folder path containing images\n",
    "image_folder = r'C:\\Users\\shrey\\OneDrive - Process Point Technologies\\vlm-ppe-analysis-toolkit\\data\\ppe-custom-data'\n",
    "\n",
    "# Model Save Path\n",
    "model_cache_dir = r\"C:\\Users\\shrey\\OneDrive - Process Point Technologies\\vlm-ppe-analysis-toolkit\\models\"\n",
    "model_name = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "\n",
    "# Load Model & Processor\n",
    "model, processor = load_model(model_name, model_cache_dir)\n",
    "\n",
    "# Process images\n",
    "results = process_folder(image_folder, model, processor)  # Process all images\n",
    "\n",
    "# Generate and display HTML in notebook\n",
    "html_content = generate_html(results)\n",
    "display(HTML(html_content))\n",
    "\n",
    "# Save HTML file\n",
    "save_html(html_content, model_name, r\"C:\\Users\\shrey\\OneDrive - Process Point Technologies\\vlm-ppe-analysis-toolkit\\results\\qwen2_vl_analysis_results.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
